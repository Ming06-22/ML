{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar10_CNN","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN7o+5n6zF5iyDhGiQTDn8f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Zy7SXH4CdRE","executionInfo":{"status":"ok","timestamp":1656669853328,"user_tz":-480,"elapsed":168971,"user":{"displayName":"余明昌","userId":"16390494860865880575"}},"outputId":"dd395b23-1a7a-497e-b27d-498c72d7e1af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 13s 0us/step\n","170508288/170498071 [==============================] - 13s 0us/step\n","Epoch 1/50\n","80/80 - 14s - loss: 1.8832 - accuracy: 0.3152 - val_loss: 1.5861 - val_accuracy: 0.4338 - 14s/epoch - 170ms/step\n","Epoch 2/50\n","80/80 - 2s - loss: 1.5030 - accuracy: 0.4537 - val_loss: 1.3777 - val_accuracy: 0.5180 - 2s/epoch - 23ms/step\n","Epoch 3/50\n","80/80 - 2s - loss: 1.3553 - accuracy: 0.5105 - val_loss: 1.2538 - val_accuracy: 0.5676 - 2s/epoch - 21ms/step\n","Epoch 4/50\n","80/80 - 2s - loss: 1.2492 - accuracy: 0.5534 - val_loss: 1.1544 - val_accuracy: 0.5973 - 2s/epoch - 22ms/step\n","Epoch 5/50\n","80/80 - 2s - loss: 1.1768 - accuracy: 0.5792 - val_loss: 1.0825 - val_accuracy: 0.6195 - 2s/epoch - 23ms/step\n","Epoch 6/50\n","80/80 - 2s - loss: 1.1094 - accuracy: 0.6090 - val_loss: 1.0483 - val_accuracy: 0.6421 - 2s/epoch - 21ms/step\n","Epoch 7/50\n","80/80 - 2s - loss: 1.0612 - accuracy: 0.6233 - val_loss: 1.0360 - val_accuracy: 0.6423 - 2s/epoch - 22ms/step\n","Epoch 8/50\n","80/80 - 2s - loss: 1.0106 - accuracy: 0.6440 - val_loss: 0.9569 - val_accuracy: 0.6698 - 2s/epoch - 23ms/step\n","Epoch 9/50\n","80/80 - 2s - loss: 0.9764 - accuracy: 0.6554 - val_loss: 0.9344 - val_accuracy: 0.6791 - 2s/epoch - 23ms/step\n","Epoch 10/50\n","80/80 - 2s - loss: 0.9445 - accuracy: 0.6692 - val_loss: 0.8919 - val_accuracy: 0.6943 - 2s/epoch - 22ms/step\n","Epoch 11/50\n","80/80 - 2s - loss: 0.9059 - accuracy: 0.6800 - val_loss: 0.8998 - val_accuracy: 0.6893 - 2s/epoch - 23ms/step\n","Epoch 12/50\n","80/80 - 2s - loss: 0.8755 - accuracy: 0.6913 - val_loss: 0.8594 - val_accuracy: 0.7030 - 2s/epoch - 23ms/step\n","Epoch 13/50\n","80/80 - 2s - loss: 0.8408 - accuracy: 0.7024 - val_loss: 0.8472 - val_accuracy: 0.7057 - 2s/epoch - 23ms/step\n","Epoch 14/50\n","80/80 - 2s - loss: 0.8228 - accuracy: 0.7095 - val_loss: 0.8164 - val_accuracy: 0.7194 - 2s/epoch - 23ms/step\n","Epoch 15/50\n","80/80 - 2s - loss: 0.7913 - accuracy: 0.7233 - val_loss: 0.8143 - val_accuracy: 0.7199 - 2s/epoch - 25ms/step\n","Epoch 16/50\n","80/80 - 2s - loss: 0.7702 - accuracy: 0.7271 - val_loss: 0.8065 - val_accuracy: 0.7225 - 2s/epoch - 24ms/step\n","Epoch 17/50\n","80/80 - 2s - loss: 0.7529 - accuracy: 0.7344 - val_loss: 0.7940 - val_accuracy: 0.7234 - 2s/epoch - 22ms/step\n","Epoch 18/50\n","80/80 - 2s - loss: 0.7201 - accuracy: 0.7435 - val_loss: 0.7885 - val_accuracy: 0.7270 - 2s/epoch - 24ms/step\n","Epoch 19/50\n","80/80 - 2s - loss: 0.6968 - accuracy: 0.7567 - val_loss: 0.7682 - val_accuracy: 0.7339 - 2s/epoch - 22ms/step\n","Epoch 20/50\n","80/80 - 2s - loss: 0.6819 - accuracy: 0.7576 - val_loss: 0.7857 - val_accuracy: 0.7298 - 2s/epoch - 24ms/step\n","Epoch 21/50\n","80/80 - 2s - loss: 0.6521 - accuracy: 0.7707 - val_loss: 0.7603 - val_accuracy: 0.7338 - 2s/epoch - 22ms/step\n","Epoch 22/50\n","80/80 - 2s - loss: 0.6329 - accuracy: 0.7775 - val_loss: 0.7491 - val_accuracy: 0.7428 - 2s/epoch - 22ms/step\n","Epoch 23/50\n","80/80 - 2s - loss: 0.6183 - accuracy: 0.7802 - val_loss: 0.7854 - val_accuracy: 0.7330 - 2s/epoch - 24ms/step\n","Epoch 24/50\n","80/80 - 2s - loss: 0.6051 - accuracy: 0.7874 - val_loss: 0.7527 - val_accuracy: 0.7411 - 2s/epoch - 23ms/step\n","Epoch 25/50\n","80/80 - 2s - loss: 0.5813 - accuracy: 0.7942 - val_loss: 0.7373 - val_accuracy: 0.7446 - 2s/epoch - 23ms/step\n","Epoch 26/50\n","80/80 - 2s - loss: 0.5684 - accuracy: 0.8004 - val_loss: 0.7387 - val_accuracy: 0.7501 - 2s/epoch - 24ms/step\n","Epoch 27/50\n","80/80 - 2s - loss: 0.5494 - accuracy: 0.8053 - val_loss: 0.7506 - val_accuracy: 0.7456 - 2s/epoch - 24ms/step\n","Epoch 28/50\n","80/80 - 2s - loss: 0.5279 - accuracy: 0.8112 - val_loss: 0.7386 - val_accuracy: 0.7487 - 2s/epoch - 23ms/step\n","Epoch 29/50\n","80/80 - 2s - loss: 0.5187 - accuracy: 0.8152 - val_loss: 0.7347 - val_accuracy: 0.7527 - 2s/epoch - 23ms/step\n","Epoch 30/50\n","80/80 - 2s - loss: 0.4940 - accuracy: 0.8249 - val_loss: 0.7350 - val_accuracy: 0.7553 - 2s/epoch - 22ms/step\n","Epoch 31/50\n","80/80 - 2s - loss: 0.4851 - accuracy: 0.8267 - val_loss: 0.7607 - val_accuracy: 0.7467 - 2s/epoch - 23ms/step\n","Epoch 32/50\n","80/80 - 2s - loss: 0.4768 - accuracy: 0.8292 - val_loss: 0.7406 - val_accuracy: 0.7547 - 2s/epoch - 23ms/step\n","Epoch 33/50\n","80/80 - 2s - loss: 0.4544 - accuracy: 0.8379 - val_loss: 0.7497 - val_accuracy: 0.7560 - 2s/epoch - 22ms/step\n","Epoch 34/50\n","80/80 - 2s - loss: 0.4522 - accuracy: 0.8379 - val_loss: 0.7671 - val_accuracy: 0.7462 - 2s/epoch - 23ms/step\n","Epoch 35/50\n","80/80 - 2s - loss: 0.4341 - accuracy: 0.8457 - val_loss: 0.7424 - val_accuracy: 0.7559 - 2s/epoch - 23ms/step\n","Epoch 36/50\n","80/80 - 2s - loss: 0.4241 - accuracy: 0.8492 - val_loss: 0.7421 - val_accuracy: 0.7589 - 2s/epoch - 23ms/step\n","Epoch 37/50\n","80/80 - 2s - loss: 0.4124 - accuracy: 0.8540 - val_loss: 0.7385 - val_accuracy: 0.7585 - 2s/epoch - 23ms/step\n","Epoch 38/50\n","80/80 - 2s - loss: 0.4016 - accuracy: 0.8576 - val_loss: 0.7457 - val_accuracy: 0.7619 - 2s/epoch - 23ms/step\n","Epoch 39/50\n","80/80 - 2s - loss: 0.3906 - accuracy: 0.8614 - val_loss: 0.7724 - val_accuracy: 0.7545 - 2s/epoch - 23ms/step\n","Epoch 40/50\n","80/80 - 2s - loss: 0.3772 - accuracy: 0.8642 - val_loss: 0.7518 - val_accuracy: 0.7591 - 2s/epoch - 23ms/step\n","Epoch 41/50\n","80/80 - 2s - loss: 0.3759 - accuracy: 0.8659 - val_loss: 0.7754 - val_accuracy: 0.7559 - 2s/epoch - 21ms/step\n","Epoch 42/50\n","80/80 - 2s - loss: 0.3664 - accuracy: 0.8690 - val_loss: 0.7487 - val_accuracy: 0.7630 - 2s/epoch - 23ms/step\n","Epoch 43/50\n","80/80 - 2s - loss: 0.3548 - accuracy: 0.8753 - val_loss: 0.7803 - val_accuracy: 0.7572 - 2s/epoch - 21ms/step\n","Epoch 44/50\n","80/80 - 2s - loss: 0.3416 - accuracy: 0.8780 - val_loss: 0.7849 - val_accuracy: 0.7500 - 2s/epoch - 23ms/step\n","Epoch 45/50\n","80/80 - 2s - loss: 0.3378 - accuracy: 0.8809 - val_loss: 0.7807 - val_accuracy: 0.7595 - 2s/epoch - 21ms/step\n","Epoch 46/50\n","80/80 - 2s - loss: 0.3263 - accuracy: 0.8814 - val_loss: 0.7700 - val_accuracy: 0.7612 - 2s/epoch - 22ms/step\n","Epoch 47/50\n","80/80 - 2s - loss: 0.3271 - accuracy: 0.8818 - val_loss: 0.7755 - val_accuracy: 0.7571 - 2s/epoch - 26ms/step\n","Epoch 48/50\n","80/80 - 2s - loss: 0.3184 - accuracy: 0.8865 - val_loss: 0.7853 - val_accuracy: 0.7602 - 2s/epoch - 26ms/step\n","Epoch 49/50\n","80/80 - 2s - loss: 0.3150 - accuracy: 0.8885 - val_loss: 0.7911 - val_accuracy: 0.7613 - 2s/epoch - 23ms/step\n","Epoch 50/50\n","80/80 - 2s - loss: 0.3014 - accuracy: 0.8928 - val_loss: 0.7901 - val_accuracy: 0.7595 - 2s/epoch - 23ms/step\n","313/313 [==============================] - 1s 4ms/step - loss: 0.8166 - accuracy: 0.7559\n","Accuracy:  0.7559000253677368\n"]}],"source":["from keras.datasets import cifar10\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# load data, normalize feature, and convert label to onehot code\n","((train_data, train_label), (test_data, test_label)) = cifar10.load_data()\n","train_data = train_data / 255\n","train_label_onehot = np_utils.to_categorical(train_label)\n","test_data = test_data / 255\n","test_label_onehot = np_utils.to_categorical(test_label)\n","\n","# construct CNN model\n","model = Sequential()\n","model.add(Conv2D(input_shape = (32, 32, 3), filters = 32, kernel_size = (5, 5), padding = \"same\", activation = \"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2)))\n","model.add(Dropout(0.3))\n","model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding = \"same\", activation = \"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2)))\n","model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(units = 256, kernel_initializer = \"normal\", activation = \"relu\"))\n","model.add(Dropout(0.3))\n","model.add(Dense(units = 10, kernel_initializer = \"normal\", activation = \"softmax\"))\n","\n","# set training mode and start training\n","model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","model.fit(x = train_data, y = train_label_onehot, validation_split = 0.2, epochs = 50, batch_size = 500, verbose = 2)\n","\n","# evaluate the model\n","evaluate = model.evaluate(test_data, test_label_onehot)\n","print(\"Accuracy: \", evaluate[1])\n","\n","# save model\n","model.save(\"cifarModel.h5\")"]},{"cell_type":"code","source":["from keras.models import load_model\n","import glob\n","import cv2\n","import numpy as np\n","from keras.utils import np_utils\n","\n","# load model and pictures to predict\n","model = load_model(\"cifarModel.h5\")\n","files = glob.glob(\"*.jpg\")\n","test_data = []\n","test_label = []\n","\n","# put the pictures in to list and give them labels\n","for file in files:\n","  img = cv2.imread(file)\n","  test_data.append(img)\n","  label = file[-7: -6]\n","  test_label.apped(int(label))\n","\n","# convert to appropriate data type, normalize features, and convert labels to onehot code\n","test_data = np.array(test_data)\n","test_label = np.array(test_label)\n","test_data = test_data / 255\n","test_label_onehot = np_utils.to_categorical(test_label)\n","\n","# evaluate the model\n","evaluate = model.evaluate(test_data, test_label_onehot)\n","print(\"Accuracy: \", evaluate[1])\n","\n","# do prediction\n","prediction = model.predict(test_data)\n","print(\"Real value: \", test_label)\n","print(\"Predict value: \", np.argmax(prediction, axis = 1))"],"metadata":{"id":"swlrJLt2OCCS"},"execution_count":null,"outputs":[]}]}